# ğŸ§© Fullstack Todo-App mit Docker Compose

Dieses Projekt ist eine einfache Fullstack-Webanwendung zur Verwaltung von Todos. Sie besteht aus:

- einem React-Frontend (Vite + Tailwind, ausgeliefert Ã¼ber Nginx)
- einem Express-Backend (Node.js mit PostgreSQL-Anbindung)
- einer PostgreSQL-Datenbank

Alle Services laufen in Docker-Containern und werden mit Docker Compose orchestriert.

## ğŸš€ Schnellstart

### 1. `.env`-Datei anlegen

Erstelle im Projekt-Root eine `.env`-Datei mit folgendem Inhalt:

```env
POSTGRES_USER=**
POSTGRES_PASSWORD=**
POSTGRES_DB=**
```

## ğŸš€ Stack starten

docker-compose up --build -d

## ğŸ§± Schema in der Datenbank initialisieren

docker cp backend/sql/initial_schema.sql postgres-db:/tmp/initial_schema.sql
MSYS_NO_PATHCONV=1 docker exec -u postgres postgres-db psql -U todoapp -d todos -f /tmp/initial_schema.sql

## ğŸŒ Anwendung im Browser Ã¶ffnen

http://localhost:8080

## ğŸ“ Verzeichnisstruktur

- `frontend/` â€“ React-Frontend mit Vite + Tailwind, Build via Dockerfile  
- `backend/` â€“ Express-API mit PostgreSQL-Anbindung via `pg`  
- `backend/sql/initial_schema.sql` â€“ SQL-Datei zum manuellen Schema-Import  
- `.env` â€“ Umgebungsvariablen fÃ¼r Datenbankzugang  
- `docker-compose.yml` â€“ Orchestrierung aller Services  

## ğŸ”Œ API-Endpunkte

| Methode | Route            | Beschreibung                |
|---------|------------------|-----------------------------|
| GET     | /api/todos       | Alle Todos abrufen          |
| GET     | /api/todos/:id   | Todo nach ID abrufen        |
| POST    | /api/todos       | Neues Todo erstellen        |
| DELETE  | /api/todos/:id   | Todo lÃ¶schen                |

## ğŸ§  Technologien

- Docker & Docker Compose  
- Node.js & Express  
- PostgreSQL  
- React (Vite)  
- Tailwind CSS  
- Winston (fÃ¼r Logging)  
- pg (Node PostgreSQL Client)  

## ğŸ› ï¸ Features

- Nginx als Reverse Proxy fÃ¼r API-Routen  
- ENV-Verwaltung mit `.env` und Docker Compose  
- persistente Volumes fÃ¼r DB und Backend-Dateien  
- SQL-Abfragen mit Parametrisierung zum Schutz vor SQL-Injection  
- saubere Projektstruktur mit Service-/Controller-Pattern  
- Logging von Datenbankkonfiguration (Passwort zensiert)  

## ğŸ§¹ Bereinigen

```bash
docker-compose down -v
```
### ğŸ§  Teamprozess zur Sicherstellung der Stack-StabilitÃ¤t

Unser Team hat zu Beginn gemeinsam den Aufbau des Full-Stack-Projekts besprochen und klare Verantwortlichkeiten verteilt (z.â€¯B. Datenbank, API, Frontend, Docker-Setup). Um sicherzustellen, dass alle Komponenten stabil miteinander funktionieren, haben wir uns regelmÃ¤ÃŸig im Team ausgetauscht und gegenseitig Code-Reviews gemacht. Besonders wichtig war, dass alle mit der gleichen `.env`-Datei gearbeitet haben, um konsistente Verbindungen zur PostgreSQL-Datenbank zu gewÃ¤hrleisten.

Wir haben den Docker-Compose-Stack mehrfach gemeinsam getestet â€“ vor allem die Ãœbergabe der ENV-Variablen, den Start der Container in der richtigen Reihenfolge und die Reaktion der API-Endpunkte im Frontend. Die Healthchecks haben wir so eingebaut, dass das Backend erst startet, wenn die Datenbank wirklich bereit ist. Dadurch konnten wir viele typische Startprobleme vermeiden und sicherstellen, dass CRUD-Anfragen stabil funktionieren.

### âš ï¸ Technische Herausforderungen & LÃ¶sungen

Eine der grÃ¶ÃŸten Herausforderungen war die Umstellung des Backends von File-basiertem Speichern auf echte Datenbankabfragen mit PostgreSQL. Dabei mussten wir sicherstellen, dass alle CRUD-Operationen (Erstellen, Lesen, LÃ¶schen) korrekt Ã¼ber die `pg`-Bibliothek ablaufen und die Datenbankverbindung Ã¼ber Umgebungsvariablen richtig gesetzt ist.

Ein konkretes Problem war ein Fehler beim Ãœbergabeformat des Datenbankpassworts: In einem Fall wurde `process.env.DB_PASSWORD` als `undefined` gelesen, weil die `.env`-Datei nicht korrekt eingebunden war. Wir haben das gemeinsam debuggt, indem wir Umgebungsvariablen im laufenden Container mit `printenv` geprÃ¼ft haben.

Auch die Umstellung auf parametrisierte SQL-Abfragen im Backend war anfangs fehleranfÃ¤llig â€“ insbesondere bei der Anzahl der Ã¼bergebenen Parameter. Durch gegenseitige Code-Reviews haben wir solche Fehler schneller erkannt und gelÃ¶st. Wichtig war auch das gemeinsame Testen der Endpunkte Ã¼ber das Frontend, um sicherzustellen, dass die Abfragen bis zur Datenbank durchgehen.

### ğŸ¤ Vorteile der Zusammenarbeit beim Debugging & Integration

Durch die Zusammenarbeit im Team konnten wir Probleme deutlich schneller erkennen und lÃ¶sen. WÃ¤hrend man allein oft in einer Sackgasse steckt, bringt das gemeinsame Debugging verschiedene Blickwinkel zusammen. So hat zum Beispiel eine Person entdeckt, dass die API zwar erreichbar war, aber durch einen Fehler in der `docker-compose.yml` nicht mit der Datenbank kommunizieren konnte.

Auch bei der Integration von Frontend und Backend hat die geteilte Verantwortung geholfen: Eine Person konnte den Request im Frontend nachverfolgen, wÃ¤hrend die andere parallel das Logging im Backend kontrolliert hat. So konnten wir API-Probleme effizient eingrenzen.

Insgesamt war der gegenseitige Austausch bei Fragen rund um `pg`, SQL-Fehler, CORS oder Routing im Nginx-Proxy extrem hilfreich. Durch die geteilte Verantwortung war der Fortschritt kontinuierlich â€“ auch wenn jemand mal an einem Thema hÃ¤ngen blieb.

### Beschreibe den finalen Zustand deines Stacks (Fullstack mit DB, CRUD, Healthchecks)

Der finale Zustand meines Projekts besteht aus einem vollstÃ¤ndigen Fullstack-Setup mit drei zentralen Komponenten: dem React-Frontend, einer Express-API als Backend und einer PostgreSQL-Datenbank zur Datenpersistenz. 

Alle Services laufen in eigenen Containern und werden Ã¼ber Docker Compose orchestriert. Die Kommunikation zwischen Frontend und Backend erfolgt Ã¼ber Nginx als Reverse Proxy. Das Backend ist so aufgebaut, dass alle CRUD-Operationen auf die Datenbank zugreifen â€“ das heiÃŸt, Todos werden nicht mehr in einer JSON-Datei gespeichert, sondern direkt in der PostgreSQL-Datenbank.

ZusÃ¤tzlich ist ein Healthcheck fÃ¼r den Datenbank-Container konfiguriert, damit sichergestellt ist, dass die Datenbank betriebsbereit ist, bevor das Backend startet.


### ErklÃ¤re, wie man deinen Stack startet und die vollstÃ¤ndige Ende-zu-Ende FunktionalitÃ¤t (alle CRUD-Operationen) sowie den Status der Healthchecks verifiziert

Um den Stack zu starten, reicht der Befehl:

```bash
docker-compose up --build -d
```

docker cp backend/sql/initial_schema.sql postgres-db:/tmp/initial_schema.sql
MSYS_NO_PATHCONV=1 docker exec -u postgres postgres-db psql -U todoapp -d todos -f /tmp/initial_schema.sql

Um das Schema in die Postgresdatenbank zu Ã¼bertagen

docker cp backend/sql/initial_schema.sql postgres-db:/tmp/initial_schema.sql
MSYS_NO_PATHCONV=1 docker exec -u postgres postgres-db psql -U todoapp -d todos -f /tmp/initial_schema.sql

AnschlieÃŸend kann die Anwendung im Browser Ã¼ber http://localhost:8080 aufgerufen werden. Dort ist das React-Frontend zu sehen, das alle API-Aufrufe Ã¼ber /api/... an das Backend weiterleitet. Man kann Todos erstellen, abrufen und lÃ¶schen â€“ alle diese CRUD-Operationen werden direkt in der PostgreSQL-Datenbank gespeichert.
Ob die Healthchecks erfolgreich sind, lÃ¤sst sich Ã¼ber den Befehl docker-compose ps prÃ¼fen: Die Statusspalte zeigt, ob alle Container laufen und insbesondere, ob der postgres-db-Service als â€healthyâ€œ markiert ist.
AuÃŸerdem zeigen die Logs (docker-compose logs backend), ob das Backend erfolgreich gestartet ist und eine Verbindung zur Datenbank aufbauen konnte.

![Screenshot](Screenshot.png)

# ğŸŒŸ Docker Swarm Deployment

### ğŸ—ï¸ Stack-Architektur in Swarm

Unser Stack lÃ¤uft auf einem Docker Swarm Cluster mit:
- 1 Manager-Node fÃ¼r die Orchestrierung
- 3 Worker-Nodes mit spezifischen Rollen:
  - worker1: Frontend-Service (Nginx)
  - worker2: Backend-Service (Node.js)
  - worker3: Datenbank-Service (PostgreSQL)

Jeder Service wird mittels Placement Constraints und Labels auf dedizierten Nodes platziert.

### ğŸš€ Einrichtung des Swarm Clusters

1. VMs mit Multipass erstellen:
```bash
./setup-multipass.sh
```

2. Images bauen und zu Docker Hub pushen:
```bash
# Images bauen
docker build -t jigglyy/frontend:latest ./frontend
docker build -t jigglyy/backend:latest ./backend

# Zur Registry pushen
docker push jigglyy/frontend:latest
docker push jigglyy/backend:latest
```

3. Stack deployen:
```bash
./deploy.sh
```

### ğŸ” Deployment Ã¼berprÃ¼fen

Service-Status und Platzierung prÃ¼fen:
```bash
# Service-Status anzeigen
multipass exec manager -- docker service ls

# Detaillierte Service-Platzierung prÃ¼fen
multipass exec manager -- docker stack ps myapp

# Service-Logs anzeigen
multipass exec manager -- docker service logs myapp_frontend
multipass exec manager -- docker service logs myapp_backend
multipass exec manager -- docker service logs myapp_database
```

### ğŸ› Debug-Leitfaden

1. Node-Labels prÃ¼fen:
```bash
multipass exec manager -- docker node ls --filter role=manager
multipass exec manager -- docker node inspect worker1 --format '{{.Spec.Labels}}'
```

2. Netzwerk-KonnektivitÃ¤t verifizieren:
```bash
multipass exec manager -- docker network ls
multipass exec manager -- docker network inspect myapp_todo-app-network
```

3. Service-Gesundheit Ã¼berwachen:
```bash
multipass exec manager -- docker service inspect myapp_database --format '{{.Status.ContainerStatus.HealthStatus}}'
```

### ğŸ¤” Reflexionsfragen

**F: Wie stellt dein Stack eine robuste Service-Platzierung sicher?**
A: Unser Stack verwendet Docker Swarm Placement Constraints und Node-Labels:
```yaml
deploy:
  placement:
    constraints:
      - node.role == worker
      - node.labels.role == frontend
```

**F: Wie handhabst du Service Discovery im Swarm?**
A: Die Services kommunizieren Ã¼ber Docker's eingebaute DNS-AuflÃ¶sung. Die Nginx-Konfiguration im Frontend-Container lÃ¶st Backend-Services Ã¼ber ihre Service-Namen auf:
```nginx
location /api/ {
    resolver 127.0.0.11 valid=30s;
    set $backend "backend";
    proxy_pass http://$backend:3000/;
}
```

**F: Welche Monitoring- und Debugging-Strategien verwendest du?**
A: Wir setzen auf:
- Health Checks fÃ¼r alle Services
- Service-Log-Ãœberwachung
- Node- und Service-Inspektion
- Netzwerk-KonnektivitÃ¤tsprÃ¼fung

### ğŸ§ª CI/CD-Ãœberlegungen

FÃ¼r Produktiv-Deployments empfehlen wir:
1. Automatisierte Image-Builds
2. Versions-Tagging
3. Blue-Green Deployments
4. Monitoring-Setup

### ğŸ“š Repository-Struktur

```
.
â”œâ”€â”€ .gitignore               # SchlieÃŸt node_modules, env-Dateien aus
â”œâ”€â”€ .dockerignore           # Optimiert Builds
â”œâ”€â”€ docker-stack.yml        # Swarm Deployment-Konfiguration
â”œâ”€â”€ setup-multipass.sh      # VM Setup-Skript
â”œâ”€â”€ deploy.sh               # Deployment-Skript
â””â”€â”€ README.md              # Diese Dokumentation
```

## Aufgabe: Lokales Kubernetes Cluster aufsetzen

### Lernziele
- Verstehen, wie ein Kubernetes Cluster lokal eingerichtet wird
- Kennenlernen der Rolle der Control Plane und der Worker Nodes
- Praktische Anwendung von `kubectl` zur Cluster-Interaktion
- Verinnerlichen der deklarativen Philosophie von Kubernetes

### Speicherort der Abgabe
Die Reflexion zu dieser Aufgabe befindet sich unter:

```plaintext
/kubernetes/k8s-intro-reflection.md
```